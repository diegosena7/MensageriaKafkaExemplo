Os três principais componentes do Kafka são:
1 - Producer (Produtor)
2 - Broker (Intermediador)
3 - Consumer (Consumidor)

Em primeiro lugar, o Producer envia mensagens para o Cluster (Kafka) , que é um intermediador em execução em um grupo
de computadores. Em seguida, os Clusters (Kafka) armazenam esses dados no registro de mensagens do Kafka.
O Consumer lê e processa as mensagens do Cluster (Kafka).

Os conceitos básicos do Apache Kafka:

1. Producer -> É a parte da aplicação responsável por enviar mensagens
2. Broker -> Atua como um intermediador de mensagens entre o Producer e o Consumer. Como o Producer e o Consumer não
interagem diretamente, usam o Broker para intermediar essa troca de mensagens.
3. Consumer -> É a parte da aplicação responsável por receber/consumir dados/mensagens produzidas pelo consumer e
disponibilizadas no Broker.
4. Cluster -> Grupo de "computadores" executando uma instância do Broker.
5. Tópico -> São grupos de mensagens dentro do Kafka. Todas as mensagens enviadas para o Kafka permanecem em um tópico.
É usado para manter a ordenação de um sistema em Kafka, pode possuir N partições e ao receber uma nova msg o Kafka
direciona a msg para uma partição específica usando sua chave (key), deixando suas respectivas msgs atreladas a suas
respectivas chaves (key) e garante a ordenação das msgs em seus tópicos.
6. Partição -> Usado como divisor dos dados/msgs de um tópico.
7. Descolcamento ->  É um número de sequência de uma mensagem em uma partição, atribuído conforme chegam e se tornam
imutáveis. O kafka armazena as msgs na ordem de chegada em uma partição, para localizar diretamente  uma msg devemos
passar 3 parâmetros que são: o nome do tópico, o número da partição e o do deslocamento.
8. Grupo de Consumers -> Usado para compartilhar o trabalho de consumir grande quantidade de mensagens e organizar
de Broker/Producer será feita a leitura das informações/dados.

OBS: Não é boa prática ter um consumer escutando/consumindo mais de 1 tópico
OBS: Internamente no Kafka, consumidores são organizados em grupos (consumer groups), com issso, nas classes de consumer
temos que indicar os grupos ao setarmos as propriedades (setProperty) usando o GROUP_ID_CONFIG na chamada do método
ConsumerConfig.
OBS: O Kafka faz o balanceamento das msgs entre os grupos que consomem de um mesmo Consumer, podemos definir o
direcionamento das msgs aos Consumers através das chaves (key).
A chave (key) é usada para distribuir a mensagem entre as partições existentes e consequentemente entre as instâncias
de um serviço dentro de um consumer group.
OBS: O número de partições em um tópico, deve ser igual ou maior que o número de Consumer Groups.

Na classe NewOrderMain estamos usando como responsável por chamar o dispacher e passar os parâmetros (tópico, key,
value).

A classe KafkaDispatcher é responsável por produzir as msgs, usa o método properties para passar as propriedades e
conectar com o servidor, usa o método send para enviar as msgs para o tópico com a chave (key) e o valor (value).

A classe KafkaService é responsável por instanciar os consumidores de msgs, cria o consumer através da classe
KafkaConsumer criamos um método run para executar o consumer e registrar os dados recebidos. Setamos as propriedades
usando o método properties, onde passamos o servidor, chave, valor e o id do grupo de consumo.

Na classe FraudDetectorService usamos um try onde instanciamos a classe KafkaService e passamos os parâmetros (groupId,
topic, parse), através do atributo service do tipo KafkaService chamamos o método run. O método parse imprime os
atributos do objeto record.

Na classe EmailService usamos um try onde instanciamos a classe KafkaService e passamos os parâmetros (groupId, topic,
parse), através do atributo service do tipo KafkaService chamamos o método run. O método parse imprime os atributos do
objeto record.

Na classe LogService criamos um consumer e usamos no método subscribe passando a classe Pattern (como expressão regular)
que ele irá "escutar" todos os tópicos do tipo ECOMMERCE, ou seja, ele irá consumir msgs de mais de um producer.
Enquanto tiver registros no atributo records ele imprime as msgs do conteúdo e setamos as propriedades através do método
properties.

Na classe ConsumerFunction criamos como interface e possui um método consume que recebe um ConsumerRecord do tipo String

Na classe KafkaService, criamos um consumer do tipo KafkaConsumer, intanciamos a classe ConsumerFunction. Criamos um
método run, onde esse método faz busca na lista de consumers para cada record encontrado na lista.




Os três principais componentes do Kafka são:
1 - Producer (Produtor)
2 - Broker (Intermediador)
3 - Consumer (Consumidor)

Em primeiro lugar, o Producer envia mensagens para o Cluster (Kafka) , que é um intermediador em execução em um grupo de computadores. Em seguida, os Clusters (Kafka) armazenam esses dados no registro de mensagens do Kafka.
O Consumer lê e processa as mensagens do Cluster (Kafka).

Os conceitos básicos do Apache Kafka:

1. Producer -> É a parte da aplicação responsável por enviar mensagens
2. Broker -> Atua como um intermediador de mensagens entre o Producer e o Consumer. Como o Producer e o Consumer não
interagem diretamente, usam o Broker para intermediar essa troca de mensagens.
3. Consumer -> É a parte da aplicação responsável por receber/consumir dados/mensagens produzidas pelo consumer e
disponibilizadas no Broker.
4. Cluster -> Grupo de "computadores" executando uma instância do Broker.
5. Tópico -> São grupos de mensagens dentro do Kafka. Todas as mensagens enviadas para o Kafka permanecem em um tópico.
É usado para manter a ordenação de um sistema em Kafka, pode possuir N partições e ao receber uma nova msg o Kafka
direciona a msg para uma partição específica usando sua chave (key), deixando suas respectivas msgs atreladas a suas
respectivas chaves (key) e garante a ordenação das msgs em seus tópicos.
6. Partição -> Usado como divisor dos dados/msgs de um tópico.

7. Descolcamento ->  É um número de sequência de uma mensagem em uma partição, atribuído conforme chegam e se tornam
imutáveis. O kafka armazena as msgs na ordem de chegada em uma partição, para localizar diretamente  uma msg devemos
passar 3 parâmetros que são: o nome do tópico, o número da partição e o do deslocamento.
8. Grupo de Consumers -> Usado para compartilhar o trabalho de consumir grande quantidade de mensagens e organizar
de Broker/Producer será feita a leitura das informações/dados.

Na classe NewOrderMain.java classe responsável por iniciar a chamada di serviço de mensageria (KafkaDispacher)

Na classe KafkaDispacher responsável por criar os produtores de msgs, usamos a classe KafkaProducer para criar nosso
producer que irá produzir as msgs, setamos as propriedades através do método properties, usamos o GsonSerializer para
serializar o objeto em Json e usamos o método send para enviar as msgs passando como parâmetro topic, key e value.

Na classe KafkaService responsável por realizar o envio das msgs aos serviços/classes de consumers

Criamos as classes GsonSerializer e GsonDeserializer para trabalhar a serialização e deserialização dos objetos

Criamos um módulo para cada microservice desenvolvido.

OBS: Não é boa prática ter um consumer escutando/consumindo mais de 1 tópico
OBS: Internamente no Kafka, consumidores são organizados em grupos, com issso, nas classes de consumer temos que
indicar os grupos ao setarmos as propriedades (setProperty) usando o GROUP_ID_CONFIG na chamada do método ConsumerConfig.


